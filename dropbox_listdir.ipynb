{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5478697a",
   "metadata": {},
   "source": [
    "The goal is to get all the paths from a directory (and its subdirs) in dropbox, then propose for each a new location and a new filename.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e394e10f",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d1f388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from utils.filename_reader import create_filename_dict, remove_extension\n",
    "import json\n",
    "\n",
    "import sys\n",
    "import dropbox\n",
    "from dropbox.files import WriteMode\n",
    "from dropbox.exceptions import ApiError, AuthError\n",
    "\n",
    "from tokens import ACCESS_TOKEN\n",
    "\n",
    "# Add OAuth2 access token here.\n",
    "# You can generate one for yourself in the App Console.\n",
    "# See <https://blogs.dropbox.com/developers/2014/05/generate-an-access-token-for-your-own-account/>\n",
    "TOKEN = ACCESS_TOKEN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddd3b26",
   "metadata": {},
   "source": [
    "# API token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd50f1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a Dropbox object...\n"
     ]
    }
   ],
   "source": [
    "if (len(TOKEN) == 0):\n",
    "    sys.exit(\"ERROR: Looks like you didn't add your access token. \"\n",
    "        \"Open up backup-and-restore-example.py in a text editor and \"\n",
    "        \"paste in your token in line 14.\")\n",
    "\n",
    "    # Create an instance of a Dropbox class, which can make requests to the API.\n",
    "print(\"Creating a Dropbox object...\")\n",
    "with dropbox.Dropbox(TOKEN) as dbx:\n",
    "\n",
    "    # Check that the access token is valid\n",
    "    try:\n",
    "        dbx.users_get_current_account()\n",
    "    except AuthError:\n",
    "        sys.exit(\"ERROR: Invalid access token; try re-generating an \"\n",
    "            \"access token from the app console on the web.\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf03eef",
   "metadata": {},
   "source": [
    "# Get the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dd6f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPRECATED\n",
    "\n",
    "def get_all_paths(dir):\n",
    "    all_paths = []\n",
    "    for entry in dbx.files_list_folder(dir).entries:\n",
    "        if type(entry) == dropbox.files.FolderMetadata:\n",
    "            all_paths += get_all_paths(entry.path_display)\n",
    "        else:\n",
    "            all_paths.append(entry.path_display)\n",
    "    return all_paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7f3d779",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dropbox_filesystem import get_all_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b12eaa0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a Dropbox object...\n",
      "Creating a Dropbox object...\n",
      "/source/REEVOID_PILOT_01_MRI_NIFTI/Resting_State/REEVOID_PILOT_01_MRI_RestingState_Lumbar_20250528145351_7.nii.gz\n",
      "/source/REEVOID_PILOT_01_MRI_NIFTI/Resting_State/REEVOID_PILOT_01_MRI_RestingState_Lumbar_20250528145351_7.json\n",
      "\n",
      "\n",
      "Creating a Dropbox object...\n",
      "Creating a Dropbox object...\n",
      "/source/REEVOID_PILOT_01_MRI_NIFTI/Resting_State/REEVOID_PILOT_01_MRI_RestingState_Lumbar_20250528145351_7.nii.gz\n",
      "/source/REEVOID_PILOT_01_MRI_NIFTI/Resting_State/REEVOID_PILOT_01_MRI_RestingState_Lumbar_20250528145351_7.json\n",
      "\n",
      "\n",
      "Creating a Dropbox object...\n",
      "Creating a Dropbox object...\n",
      "Creating a Dropbox object...\n",
      "/source/REEVOID_PILOT_01_MRI_NIFTI/Resting_State/REEVOID_PILOT_01_MRI_RestingState_Lumbar_20250528145351_7.nii.gz\n",
      "/source/REEVOID_PILOT_01_MRI_NIFTI/Resting_State/REEVOID_PILOT_01_MRI_RestingState_Lumbar_20250528145351_7.json\n",
      "/source/Reevoid_Martin_fMRI_interoperability.zip\n",
      "/source/PhysioLogFiles_fMRI_Martin.zip\n"
     ]
    }
   ],
   "source": [
    "l = get_all_paths('/source/REEVOID_PILOT_01_MRI_NIFTI', TOKEN)\n",
    "for path in l:\n",
    "    print(path)\n",
    "print('\\n')\n",
    "\n",
    "l = get_all_paths('/source/REEVOID_PILOT_01_MRI_NIFTI/', TOKEN)\n",
    "for path in l:\n",
    "    print(path)\n",
    "print('\\n')\n",
    "\n",
    "l = get_all_paths('/source/', TOKEN)\n",
    "for path in l:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc93037",
   "metadata": {},
   "source": [
    "# Save jsons with infos and new paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232a838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPRECATED\n",
    "participants_dict = {\n",
    "    \"REEVOID_001\": \"sub-01\",\n",
    "    \"REEVOID_PILOT_01\": \"sub-pilot\"\n",
    "}\n",
    "\n",
    "final_data = {}\n",
    "\n",
    "for file in l:\n",
    "    print(file)\n",
    "    final_data[file] = create_filename_dict(file, participants_dict, sub='sub_pilot',type='func', category='resting_state')\n",
    "print('done')\n",
    "\n",
    "with open('file_infos/test.json', 'w') as f:\n",
    "    json.dump(final_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dad96b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a Dropbox object...\n",
      "Creating a Dropbox object...\n",
      "Creating a Dropbox object...\n",
      "/source/REEVOID_PILOT_01_MRI_NIFTI/Resting_State/REEVOID_PILOT_01_MRI_RestingState_Lumbar_20250528145351_7.nii.gz\n",
      "/source/REEVOID_PILOT_01_MRI_NIFTI/Resting_State/REEVOID_PILOT_01_MRI_RestingState_Lumbar_20250528145351_7.json\n",
      "/source/Reevoid_Martin_fMRI_interoperability.zip\n",
      "/source/PhysioLogFiles_fMRI_Martin.zip\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "from utils.save_logs import save_file_infos\n",
    "\n",
    "input_files = get_all_paths('/source/', TOKEN)\n",
    "\n",
    "save_file_infos(\n",
    "    input_files,\n",
    "    participants_dict={\n",
    "        \"REEVOID_001\": \"sub-01\",\n",
    "        \"REEVOID_PILOT_01\": \"sub-pilot\"\n",
    "    },\n",
    "    out_path='file_infos/test-01.json',\n",
    "    sub='sub_pilot',type='func', category='resting_state'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61151286",
   "metadata": {},
   "source": [
    "## Correct new paths for localizer/other metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eb0f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_infos_path = 'file_infos/test.json'\n",
    "out_path = 'file_infos/jsons_to_data/test.json'\n",
    "\n",
    "jsons_dict = {}\n",
    "\n",
    "data_dict = {}\n",
    "\n",
    "out_dict = {}\n",
    "\n",
    "with open(file_infos_path, 'r') as f:\n",
    "    file_infos = json.load(f)\n",
    "    all_files = file_infos.keys()\n",
    "    for file in all_files:\n",
    "        if file_infos[file]['extension'] == '.json':\n",
    "            jsons_dict[file] = file_infos[file]\n",
    "        else:\n",
    "            data_dict[file] = file_infos[file]\n",
    "\n",
    "for json_file in jsons_dict.keys():\n",
    "    json_filename = json_file.split('/')[-1][:-len('.json')]\n",
    "    out_dict[json_file] = []\n",
    "    for data_file in data_dict.keys():\n",
    "        filename = data_file.split('/')[-1]\n",
    "        if json_filename in filename:\n",
    "            out_dict[json_file].append(data_file)\n",
    "\n",
    "with open(out_path, 'w') as f:\n",
    "    json.dump(out_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad2a932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.save_logs import save_jsons_to_data\n",
    "\n",
    "save_jsons_to_data(\n",
    "    file_infos_path='file_infos/test-01.json',\n",
    "    jsons_to_data_path='file_infos/jsons_to_data/test-01.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb289f17",
   "metadata": {},
   "source": [
    "**TO DO:**\n",
    "> Manually correct the json in `out_path` to match each json to its correct data file (usually nifti)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be50a3a9",
   "metadata": {},
   "source": [
    "## Change the file infos to match jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e02d7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPRECATED\n",
    "from utils.filename_reader import remove_extension\n",
    "\n",
    "file_infos_path = 'file_infos/test.json'\n",
    "corrected_file_infos_path = 'file_infos/test_corrected.json'\n",
    "jsons_to_data_path = 'file_infos/jsons_to_data/test.json'\n",
    "\n",
    "with open(file_infos_path, 'r') as f:\n",
    "    file_infos = json.load(f)\n",
    "\n",
    "with open(jsons_to_data_path, 'r') as f:\n",
    "    jsons_to_data = json.load(f)\n",
    "\n",
    "for json_file in jsons_to_data.keys():\n",
    "    assert len(jsons_to_data[json_file])<=1\n",
    "    if len(jsons_to_data[json_file])==1:\n",
    "        matching_file = jsons_to_data[json_file][0]\n",
    "        json_file_infos = file_infos[matching_file].copy()\n",
    "        json_file_infos['extension'] = '.json'\n",
    "        data_new_path = json_file_infos['new_path']\n",
    "        json_new_path = remove_extension(data_new_path) + '.json'\n",
    "\n",
    "        json_file_infos['new_path'] = json_new_path\n",
    "        file_infos[json_file] = json_file_infos\n",
    "\n",
    "with open(corrected_file_infos_path, 'w') as f:\n",
    "    json.dump(file_infos, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32d2023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.save_logs import correct_file_infos_with_matching_metadata\n",
    "\n",
    "correct_file_infos_with_matching_metadata(\n",
    "    file_infos_path = 'file_infos/test-01.json',\n",
    "    jsons_to_data_path = 'file_infos/jsons_to_data/test-01.json',\n",
    "    corrected_file_infos_path = 'file_infos/test-01_corrected.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e98674",
   "metadata": {},
   "source": [
    "# Save `paths.txt` and `recap.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b2704f",
   "metadata": {},
   "source": [
    "## `paths.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff26ec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_paths_file(file_infos_path, out_path, old_prefix='', new_prefix=''):\n",
    "\n",
    "    with open(file_infos_path,'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    out_dirs = '/'.join(out_path.split('/')[:-1])\n",
    "    try:\n",
    "        os.makedirs(out_dirs)\n",
    "        with open(out_path,'w') as f:\n",
    "            for file in data.keys():\n",
    "                f.write('~' + old_prefix + data[file]['old_path'] + ', ~/' + new_prefix + data[file]['new_path'])\n",
    "                f.write('\\n')\n",
    "    except:\n",
    "        with open(out_path,'a') as f:\n",
    "            for file in data.keys():\n",
    "                f.write('~' + data[file]['old_path'] + ', ~/' + data[file]['new_path'])\n",
    "                f.write('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbdd0861",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.save_logs import write_paths_file\n",
    "\n",
    "file_infos_path = 'file_infos/test-01_corrected.json'\n",
    "out_path = 'paths/test_01-corrected.txt'\n",
    "\n",
    "write_paths_file(file_infos_path, out_path, old_prefix='', new_prefix='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f06829",
   "metadata": {},
   "source": [
    "## `recap.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d72f829e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_general_recap_file(file_infos_path, out_path, new_prefix=''):\n",
    "\n",
    "    with open(file_infos_path,'r') as f:\n",
    "        file_infos = json.load(f)\n",
    "    \n",
    "    out_dirs = '/'.join(out_path.split('/')[:-1])\n",
    "    out_data = {}\n",
    "\n",
    "    try:\n",
    "        with open(out_path,'w') as f:\n",
    "            for file in file_infos.keys():\n",
    "                type = file_infos[file]['type']\n",
    "                new_path = new_prefix + file_infos[file]['new_path']\n",
    "                sub = file_infos[file]['sub']\n",
    "                if sub not in out_data.keys():\n",
    "                    out_data[sub] = {}\n",
    "                if type in out_data[sub].keys():\n",
    "                    out_data[sub][type].append(new_path)\n",
    "                else:\n",
    "                    out_data[sub][type] = [new_path]\n",
    "            json.dump(out_data, f, indent=4)\n",
    "    except:\n",
    "        try:\n",
    "            os.makedirs(out_dirs)\n",
    "        finally:\n",
    "            with open(out_path,'w') as f:\n",
    "                for file in file_infos.keys():\n",
    "                    type = file_infos[file]['type']\n",
    "                    new_path = new_prefix + file_infos[file]['new_path']\n",
    "                    sub = file_infos[file]['sub']\n",
    "                    if sub not in out_data.keys():\n",
    "                        out_data[sub] = {}\n",
    "                    if type in out_data[sub].keys():\n",
    "                        out_data[sub][type].append(new_path)\n",
    "                    else:\n",
    "                        out_data[sub][type] = [new_path]\n",
    "                json.dump(out_data, f, indent=4)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9cef352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.save_logs import write_general_recap_file\n",
    "\n",
    "write_general_recap_file(\n",
    "    file_infos_path='file_infos/test-01_corrected.json',\n",
    "    out_path='recaps/recap_01.json',\n",
    "    new_prefix=''\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed985a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_general_recaps(input_files, out_path):\n",
    "    out_data = {}\n",
    "    for file in input_files:\n",
    "        with open(file, 'r') as f:\n",
    "            file_data = json.load(f)\n",
    "        for sub in file_data.keys():\n",
    "            if sub not in out_data.keys():\n",
    "                out_data[sub] = file_data[sub]\n",
    "            else:\n",
    "                for file_type in file_data[sub].keys():\n",
    "                    if file_type not in out_data[sub].keys():\n",
    "                        out_data[sub][file_type] = file_data[sub][file_type]\n",
    "                    else:\n",
    "                        assert type(out_data[sub][file_type]) == list\n",
    "                        for new_path in file_data[sub][file_type]:\n",
    "                            if new_path not in out_data[sub][file_type]:\n",
    "                                out_data[sub][file_type].append(new_path)\n",
    "    try:\n",
    "        with open(out_path, 'w') as f:\n",
    "            json.dump(out_data, f, indent=4)\n",
    "    except:\n",
    "        out_dirs = '/'.join(out_path.split('/')[:-1])\n",
    "        os.makedirs(out_dirs)\n",
    "        with open(out_path, 'w') as f:\n",
    "            json.dump(out_data, f, indent=4)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0217d76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.save_logs import merge_general_recaps\n",
    "\n",
    "merge_general_recaps(\n",
    "    input_files=[\n",
    "        'recaps/recap_01.json',\n",
    "        'recaps/recap_02.json'\n",
    "    ],\n",
    "    out_path='recaps/merged_recap_test.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abd5b91",
   "metadata": {},
   "source": [
    "# Copy and rename old files to their new paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d787cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileMetadata(client_modified=datetime.datetime(2025, 6, 17, 18, 6, 34), content_hash='e5556a7e2d867e5cd33e1c73bfea5b2561c51ba635f5766a2a895777e2e19d0a', export_info=NOT_SET, file_lock_info=NOT_SET, has_explicit_shared_members=NOT_SET, id='id:KLawZ41SnG8AAAAAAAAATQ', is_downloadable=True, media_info=NOT_SET, name='sub_pilot_resting_state_id-7_bold.nii.gz', parent_shared_folder_id=NOT_SET, path_display='/target/sub_pilot/func/sub_pilot_resting_state_id-7_bold.nii.gz', path_lower='/target/sub_pilot/func/sub_pilot_resting_state_id-7_bold.nii.gz', preview_url=NOT_SET, property_groups=NOT_SET, rev='016410af3178da8000000030e305703', server_modified=datetime.datetime(2025, 10, 13, 14, 19, 4), sharing_info=NOT_SET, size=85415620, symlink_info=NOT_SET)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbx.files_copy(\n",
    "    from_path= '/source/REEVOID_PILOT_01_MRI_NIFTI/Resting_State/REEVOID_PILOT_01_MRI_RestingState_Lumbar_20250528145351_7.nii.gz',\n",
    "    to_path='/target/sub_pilot/func/sub_pilot_resting_state_id-7_bold.nii.gz'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "874e9754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a Dropbox object...\n",
      "/target\n",
      "/source\n",
      "/requirements.txt\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from utils.dropbox_filesystem import get_all_paths\n",
    "from tokens import ACCESS_TOKEN\n",
    "\n",
    "all_paths = get_all_paths('', TOKEN= ACCESS_TOKEN, recursive=False, remove_source=False)\n",
    "\n",
    "print(all_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81a900e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a Dropbox object...\n",
      "Creating a Dropbox object...\n",
      "Creating a Dropbox object...\n",
      "['/REEVOID_PILOT_01_MRI_RestingState_Lumbar_20250528145351_7.nii.gz', '/REEVOID_PILOT_01_MRI_RestingState_Lumbar_20250528145351_7.json', '/Reevoid_Martin_fMRI_interoperability.zip', '/PhysioLogFiles_fMRI_Martin.zip']\n",
      "Creating a Dropbox object...\n",
      "Creating a Dropbox object...\n",
      "Creating a Dropbox object...\n",
      "['/REEVOID_PILOT_01_MRI_RestingState_Lumbar_20250528145351_7.nii.gz', '/REEVOID_PILOT_01_MRI_RestingState_Lumbar_20250528145351_7.json', '/Reevoid_Martin_fMRI_interoperability.zip', '/PhysioLogFiles_fMRI_Martin.zip']\n"
     ]
    }
   ],
   "source": [
    "from utils.dropbox_filesystem import get_all_paths\n",
    "from tokens import ACCESS_TOKEN\n",
    "\n",
    "all_paths = get_all_paths('/source', TOKEN= ACCESS_TOKEN, recursive=True, remove_source=True)\n",
    "\n",
    "print(all_paths)\n",
    "\n",
    "all_paths = get_all_paths('/source/', TOKEN= ACCESS_TOKEN, recursive=True, remove_source=True)\n",
    "\n",
    "print(all_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64c226f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_infos_path = 'file_infos/test.json'\n",
    "\n",
    "with open(file_infos_path, 'r') as f:\n",
    "    file_infos = json.load(f)\n",
    "\n",
    "for file in file_infos.keys():\n",
    "    dbx.files_copy(\n",
    "    from_path= '/source' + file_infos[file][\"old_path\"],\n",
    "    to_path= '/target/' + file_infos[file][\"new_path\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a87e89ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/REEVOID_PILOT_01_MRI_NIFTI/Resting_State/REEVOID_PILOT_01_MRI_RestingState_Lumbar_20250528145351_7.nii.gz\n"
     ]
    }
   ],
   "source": [
    "str = '/source/REEVOID_PILOT_01_MRI_NIFTI/Resting_State/REEVOID_PILOT_01_MRI_RestingState_Lumbar_20250528145351_7.nii.gz'\n",
    "print(str[len(\"/source\"):])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
